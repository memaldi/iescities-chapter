## Guidelines for chapter preparation

__Springer series:__ Modeling and Optimization in Science & Technology

__Series Editor:__ Prof. Srikanta Patnaik


> __Title:__ "Modelling and proccessing for next generation big data technologies and applications"

#### Volume editors

* __Fatos Xhafa (corresponding editor):__ Technical University of Catalonia, Spain
* __Petraq Papajorgji & Admir Barolli:__ Canadian Institute of Tech, Albania
* __Leonard Barolli:__ Fukuoka Institute of Technology, Japan

***

### Book structure

Authors are suugested to follow the structure below, for coherence matters, although slight changes in this structure can be done:

1. Title, authors and affiliations
2. Abstract: provide a short but comprehensive abstract of the chapter
3. Introduction: authors provide an ample introduction on the problem being addressed, isssues and challenges, motivating thus the chapter
4. Preliminary concepts, background, definititions,...chapters should be self-contained
5. State of the art, literature review
6. Problem(s), issues and challenges identified
7. Proposed approach and solutions
8. Evaluation of the proposed approach (empirical studies, experimental description, computational infrastructures used, etc.)
9. Summative evluations, lessons learned
10. Further research issues
11. References
12. Index of terms
13. Acronyms/glosssary of terms

***

### Chapter book length

Chapters can have between between 20 and 35 pages long. If authors need more space, please contact book editors.

***

### Chapter book formatting style

Please use the formatting rules (from editors—document attached) and templates from Springer (attached). Both word and Latex templates are available, the use of LaTex is preferable.

__Edited Book:__ 26th March 2013

***

### Chapter book deliveries

#### 1st delivery
* __April 20th (on or before):__ Invitation to prospective authors Prospective authors will be invited to send to corresponding guest editor a two page submission with title, authors, abstract and objectives of the chapter proposal. The authors should briefly justify their propspective contribution in the book scope.
* __May 15th:__ notification (the authors will be notified about the suitability of their chapter proposal for inclusión in the book).

#### 2nd delivery
* __September 15th (on or before):__ Chapter submissions (pdf file only)
* __November 15th:__ Notification of review and feedback to authors

***

#### 3rd delivery
* __December 15th (on or before):__ Submission of revised chapters
* __December 30th:__ Final notification.

#### Final delivery
* __January 15th:__ Chapter sources and consent to publish from authors


#### Book publication
__Book publication:__ Early 2014

***

### Book scope

We are witnessing an exponential growth in data sets, coined as Big Data era. The data being generated in large Internet-based IT systems is becoming a corner-stone for enterprises, businesses, academia and all human activity fields.

There is data being generated everywhere: IT systems, biology, genomics, financial, geospatial, social networks, transportation, logistics, telecommunications, engineering, digital content, to name a few. Unlike recent past where the focus of IT systems was on functional requirements and services, now data is seen as a new asset and data technologies are needed to support IT systems with analytics and decision support.

Researchers and developers are facing challenges in dealing with this data deluge. Novel modelling, algorithms, software solutions and methodologies to cover full data cycle (from data gathering to visualization and interaction) are in need for investigation. Challenges arise due to the extremely large volumes of data, their heterogenous nature (structured & unstructured) and the pace at which data is generated requiring both offline and online processing of large streams of data. Obviously, most traditional database solutions may not be able to cope with such challenges and non-traditional database and storage solutions are imperative today.

This Springer book volume seeks contributions on new models and analytic tools for the modelling of large data sets, efficient data processing (online/offline), algorithms and analysis (mining, etc.) to enable next generation data aware systems offering quality content and innovative services in a reliable and scalable way. The book welcomes surveys critically analyzing the state of the art and envisioning the road ahead on next generatation big data technologies. Optimization models and their efficient resolution as well as performance evaluation and simulation are also interesting in the scope of the book. Finally, applications, case studies and best practices are encouraged for submission to the book.

__Topics__

Topics of interest include:

* New models for big data sets and their management
* Modelling full data life cycle: date capture, storage, processing, delivery, exploitation, visualization and interaction.
* Modelling data flows to support intelligent processing and sharing
* Advanced query models for big data
* Processing of big data sets (HPC, XML, Mining,...)
* Big Data visualisation
* Big Data sharing models
* Confidentiality, authenticity, and integrity of the big data (ensuring the long-term privacy and security of data)
* Scalable data analytics services
* Cost, economic and optimization models for big data and big data *ets
* Data software components and data re-use
* Technologies: Cloud computing systems, Data storage systems, Hadoop, Yahoo!S4, Twitter Storm
* Applications: Enterprise analytics, collaboration, event-based systems, context-aware systems, sensor networks, smart cities and environments, Energy-ware Data Centers, e-Infrastructures, social networking
* Best practices from research projects, enterprises, open data projects and infrastructures.

***

### Contact

Inquiries should be addressed to:

__Fatos Xhafa (corresponding editor):__ Technical University of Catalonia, Spain

fatos.xhafa@gmail.com / fatos@lsi.upc.edu
