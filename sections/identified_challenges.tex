\section{Identified challenges}

Taking into consideration the large amounts of data present at smart cities, data management's difficulty can be described in terms of:
\begin{itemize}
	\item Volume
	\item Variety
	\item Veracity
	\item Velocity
\end{itemize}

This four variables can also be found in \textit{Big Data}-related articles (also known as the \textit{Big Data's Vs}) \cite{zikopoulos2011understanding,russom2011big}, so it's not surprising at all that smart cities are going to deal with Big Data problems in the near future (if they are not dealing with them right now).

Data scientist need to take into account these variables, which could overlap in certain enviroments. Should this happen, each scenario will determine the most relevant factors of the process, generating un-desired drawbacks on the other ones.

\subsection{Volume}

The high amount of data used and generated by cities nowadays needs to be properly analysed, processed, stored and eventually accessible. This means conventional IT structures need to evolve, enabling scalable storage technologies, distributed querying approaches and massively parallel processing algorithms and architectures.

% Apache Hadoop, MapReduce, No-SQL...

However, big amounts of data should not be seen as a drawback attached to smart cities. The larger the datasets, the better analysis algorithms can perform, so deeper insights and conclusions should be expected as an outcome. These could ease the decission making stage.

As management consultant Peter Drucker once said: \textit{"If you can't measure it, you can't manage it"}, thus leaving no way to improve it either. This adage manifests that if you want to take care of some process, but you are not able to measure it or you can not access the data, you will not be able to manage that process. That being said, the higher amounts of data available, the greater the opportunities of obtaining useful knowledge will become.

\subsection{Variety}

Data is rarely found in a perfectly ordered and ready for processing format. Data scientist are used to work with diverse sources, which seldom fall into neat relational structures: embedded sensor data, documents, media content, social data, etc.

Variety can be found in data sources, in storage systems, in data-types to get together in a unified analytic, etc.

Taking care of data structure will lead to an easier integration step, lowering development, analytics and maintenance costs over time.

\subsection{Veracity}

There is also an increasing concern on data trustworthiness. As pointed out by \cite{buneman2013data}, \textit{data provenance is fundamental to understanding data quality}. They also highlight that established information storage systems may not be adecuate to keep semantic sense of data.

In a previous research \cite{emalditrust}, we introduced a provenance data model to be used in user-generated Linked Data datasets, which follow W3C's PROV-O ontology\footnote{http://www.w3.org/TR/prov-o/}.

Several efforts are trying to convert existing data in high quality data, providing an extra confidence layer in which data analysts can rely. 

\subsection{Velocity}

Finally, we must assume that data generation is experiencing an exponential growth. That forces our IT structure to not only tackle with volume issues, but with processing rates. A widely spread concept among data businesses is that sometimes you can not rely on five-minute-old data for your business logic.

That's why \textit{streaming data} has moved from academic fields to industry to solve velocity problems. There are two main reasons to consider streaming processing:
\begin{itemize}
	\item Sometimes, input data is too fast to store in their entirety without rocketing costs.
	% At the extreme end of the scale, the Large Hadron Collider at CERN generates so much data that scientists must discard the overwhelming majority of it — hoping hard they’ve not thrown away anything usefu
	\item If applications mandate immediate response to the data, batch processes are not suitable. Due to the rise of smartphone applications, this trend is increasingly becoming a common scenario.
\end{itemize}
